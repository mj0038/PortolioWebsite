<!DOCTYPE html>
<html>
<head>
    <title>Experience - Mridul Jhawar</title>
    <link rel="stylesheet" href="styles/experience.css">
    <link rel="stylesheet" href="styles/general.css">
</head>
<body>
    <div class="navbar">
        <a href="index.html">Home</a>
        <a href="experience.html" class="active">Experience</a>
        <a href="projects.html">Projects</a>
        <a href="contact.html">Contact</a>
    </div>

    <div class="page-container">
        <div class="content-wrap">
            <div class="content" onclick="openModal('modalProject1')">
                <div class="photo-grid">
                    <img class="company-logo" src="icons/adp-logo.png" alt="ADP Logo">
                </div>
                <div class="experience-details">
                    <h3>Application Developer Intern</h3>
                    <div class="tech-stack">
                        <span class="tech-item">Python</span>
                        <span class="tech-item">SQL</span>
                        <span class="tech-item">PySpark</span>
                        <span class="tech-item">AWS (Glue, Lambda, State Machine, S3, SQS, IAM)</span>
                        <span class="tech-item">Databricks</span>
                        <span class="tech-item">Jenkins</span>
                        <span class="tech-item">Postman</span>
                        <span class="tech-item">Terraform</span>
                        <span class="tech-item">Jira</span>
                        <span class="tech-item">Git</span>
                    </div>
                </div>
            </div>
            <div id="modalProject1" class="modal">
                <div class="modal-content">
                    <span class="close-button" onclick="closeModal('modalProject1')">&times;</span>
                    <h3>Application Developer Intern</h3>
                    <p>
                        <strong>Project 1: Streamlining ETL Workflows for a legacy system</strong><br>

                        The company was struggling with a legacy data system that was sluggish and difficult to scale. Recognizing the need for change, we set a clear goal: to refine the ETL process for seamless data migration to DynamoDB.<br><br>
            
                        Our first step was to implement AWS Glue for data orchestration, allowing for efficient and organized data flow. Next, we incorporated AWS State Machine to handle the state transitions with precision.<br><br>
            
                        To process data at scale, AWS Lambda was introduced. This was complemented by the use of PySpark within Databricks, which enabled us to tackle complex data querying and modeling challenges.<br><br>
            
                        Through these strategic enhancements to our ETL workflow, not only did we achieve a more streamlined process, but we also realized a substantial cost saving, amounting to $120K annually. This project marked a significant leap forward in our data management capabilities.
                    </p>
                    <p>
                        <strong>Project 2:  Pioneering DevOps for a New Product Launch</strong><br>

                        In our quest to launch a revolutionary product, I played a critical role in creating a DevOps framework that would lay the foundation for the future. I led the charge in API development, ensuring each was scalable and met high standards of functionality and security, which I validated through extensive testing with Postman.<br><br>

                        I was also charged with designing a resilient infrastructure using AWS services and Terraform, which allowed us to automate and replicate our setups with precision. My efforts were part of a collaborative push towards a CI/CD methodology, smoothly managed via Jenkins.<br><br>

                        The highlight of my work was the deployment of AWS Lambda functions, which enhanced data processing by 15%, a testament to the efficiency and innovation this project brought to our product development journey.
                    </p>
                </div>
            </div>
            
            <!-- Experience 2 -->
            <div class="content" onclick="openModal('modalProject2')">
                <div class="photo-grid">
                    <img class="company-logo" src="icons/FundExpert_white.jpeg" alt="ADP Logo">
                </div>
                <div class="experience-details">
                    <h3>Data Scientist</h3>
                    <div class="tech-stack">
                        <span class="tech-item">Python</span>
                        <span class="tech-item">SQL</span>
                        <span class="tech-item">PyTorch</span>
                        <span class="tech-item">AWS (Glue, Lambda, State Machine, S3, SQS, IAM)</span>
                    </div>
                </div>
            </div>
            <div id="modalProject2" class="modal">
                <div class="modal-content">
                    <span class="close-button" onclick="closeModal('modalProject2')">&times;</span>
                    <h3>Data Scientist</h3>
                    <p>
                        <strong>Project 1: Fraud Detection and Data Engineering</strong><br><br>

                        As a Data Scientist, I took on the formidable task of tackling fraud in the insurance sector, a domain plagued by deceptive claims and obscured data. My mission was to construct predictive models that could sift through billions of records and unmask fraudulent activities with precision.<br><br>
                        
                        The project commenced with the development of an intricate SQL database designed to handle vast volumes of data efficiently. Alongside this, I crafted GraphQL APIs that served as the backbone for data retrieval, allowing for intricate analysis and reporting. Rigorous test cases were formulated and executed to ensure the robustness of the APIs and the integrity of the data retrieval processes.<br><br>
                        
                        I was also responsible for orchestrating complex ETL workflows using Apache Airflow. This was no small feat, given the sheer volume of over 90 terabytes of mutual fund data that needed to be processed and analyzed.<br><br>

                        The crown jewel of my efforts was the construction of an H2o Generalized Linear Model (GLM) which achieved an adjusted R^2 of 89%, a testament to the model's predictive power. The incorporation of Lasso regularization and a series of data transformations further honed the model's accuracy, allowing us to detect nuances and patterns indicative of fraudulent behavior.<br><br>
                        
                        These endeavors were not merely technical achievements; they represented a strategic fortification against financial fraud. By leveraging data science and machine learning, I contributed to safeguarding the integrity of insurance processes, ensuring the protection of billions in assets.<br><br>
                    </p>
                </div>
            </div>
            <div class="content" onclick="openModal('modalProject3')">
                <div class="photo-grid">
                    <img class="company-logo" src="icons/DE.png" alt="ADP Logo">
                </div>
                <div class="experience-details">
                    <h3>Software Engineer - Freelancing Gig</h3>
                    <div class="tech-stack">
                        <span class="tech-item">Python</span>
                        <span class="tech-item">SQL</span>
                        <span class="tech-item">PySpark</span>
                        <span class="tech-item">AWS (Glue, Lambda, State Machine, S3, SQS, IAM)</span>
                        <span class="tech-item">Databricks</span>
                        <span class="tech-item">Jenkins</span>
                        <span class="tech-item">Postman</span>
                        <span class="tech-item">Terraform</span>
                        <span class="tech-item">Jira</span>
                        <span class="tech-item">Git</span>
                    </div>
                </div>
            </div>
            <div id="modalProject3" class="modal">
                <div class="modal-content">
                    <span class="close-button" onclick="closeModal('modalProject2')">&times;</span>
                    <h3>Data Scientist</h3>
                    <p>
                        <strong>MediOptima: Data-Driven Healthcare Solutions</strong><br><br>

                        I embarked on a transformative journey with Devesh Enterprises, a local business known for its trusted supply of generic medicines across the state of Nagpur, India. Historically rooted in traditional commerce with a strong community presence, the company had largely remained offline, operating through a network of local outlets. My role as a Data Science Intern was not just to introduce Devesh Enterprises to the digital age but to harness data science to amplify their impact and reach within the healthcare sector.<br><br>                        
                        
                        Starting from scratch, my initial challenge was to build a digital framework capable of capturing and analyzing data in a sector where every insight could translate into better health outcomes. I integrated AWS services, laying a robust foundation for data storage, processing, and analysis, thereby enabling a seamless transition from traditional record-keeping to a more sophisticated, data-driven approach.<br><br>

                        By meticulously examining sales data, patient demographics, and drug efficacy rates, I was able to derive actionable insights that directly impacted business operations. These data-driven strategies led to an optimized supply chain and more targeted distribution strategies, contributing to a significant increase in sales by 4.5%.<br><br>
                        
                        The demand for medicines is inherently dynamic and influenced by numerous factors including seasonal health trends and local health emergencies. To address this, I developed predictive models using Long Short-Term Memory (LSTM) networks and Artificial Neural Networks (ANN). These models were adept at forecasting real-time demand for various medicines, allowing Devesh Enterprises to anticipate healthcare needs and manage their inventory more effectively. This forward-thinking approach not only streamlined operations but also resulted in substantial annual savings of $10,000.<br><br>
                        
                        This experience was more than an internship; it was a mission to blend traditional healthcare business with modern data science, creating a model that was not just profitable but also responsive to the healthcare needs of the community. My stint with Devesh Enterprises marked the beginning of their journey towards a data-empowered future, ensuring that they remained a trusted provider of healthcare solutions in the ever-evolving landscape of the pharmaceutical industry.<br><br>
                    </p>
                </div>
            </div>
            <div class="content" onclick="openModal('modalProject4')">
                <div class="photo-grid">
                    <img class="company-logo" src="icons/wvu-logo.svg" alt="ADP Logo">
                </div>
                <div class="experience-details">
                    <h3> Undergraduate Data Analyst Researcher</h3>
                    <div class="tech-stack">
                        <span class="tech-item">Python</span>
                        <span class="tech-item">SQL</span>
                        <span class="tech-item">Tableau</span>
                        <span class="tech-item">CSS (Glue, Lambda, State Machine, S3, SQS, IAM)</span>
                        <span class="tech-item">HTML</span>
                        <span class="tech-item">Git</span>
                        <span class="tech-item">ImageJ</span>
                    </div>
                </div>
            </div>
            <div id="modalProject4" class="modal">
                <div class="modal-content">
                    <span class="close-button" onclick="closeModal('modalProject2')">&times;</span>
                    <h3>Data Analyst</h3>
                    <p>
                        <strong>Early Detection of Alzheimers</strong><br><br>

                        The core of my role involved the intricate analysis of genetic data from mice, a crucial element in Alzheimer's research. My challenge was to sift through this complex data to identify early genetic markers indicative of Alzheimer's. To achieve this, I utilized Tableau to create an innovative dashboard that would serve as a window into the genetic profiles of each mouse.<br><br>                        
                        
                        By meticulously monitoring and reporting on data quality, the dashboard played a pivotal role in determining the suitability of each mouse for continued participation in the experiments. This was crucial for ensuring the integrity and validity of the research.<br><br>

                        My dashboard was instrumental in the early detection process. Whenever genetic data hinted at the potential onset of Alzheimer's in a mouse, NeuroTrack would flag this information. This allowed researchers to quickly isolate and focus on these specific cases, accelerating the pace of discovery and understanding of Alzheimer's disease.<br><br>
                    </p>
                </div>
            </div>
        </div>
        
        <div class="footer">
            <p>&copy; 2023 Mridul Jhawar. All rights reserved.</p>
            <div class="social-links">
                <a href="https://github.com/mj0038" target="_blank">
                    <img src="icons/github-mark.svg" alt="GitHub">
                </a>
                <a href="https://linkedin.com/in/mridul-jhawar/" target="_blank">
                    <img src="icons/linkedin.svg.png" alt="LinkedIn">
                </a>
                <a href="https://twitter.com/yourusername" target="_blank">
                    <img src="icons/twitter.svg" alt="Twitter">
                </a>
            </div>
        </div>
    </div>
    <script>
        function openModal(modalId) {
            document.getElementById(modalId).style.display = "block";
        }

        function closeModal(modalId) {
            document.getElementById(modalId).style.display = "none";
        }

        window.onclick = function(event) {
            if (event.target.className === "modal") {
                event.target.style.display = "none";
            }
        }
    </script>
</body>
</html>
